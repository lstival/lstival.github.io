---
layout: default
title: Research Interests - Leandro Stival
description: Leandro Stival - Ph.D. in Computer Science specializing in Self-Supervised Learning
keywords: machine learning, deep learning, computer vision, video colorization, self-supervised learning, research, AI
---
<article class="page-content">
    <header class="page-header">
        <h1>Research Interests</h1>
    </header>

    <div class="page-body">
        <h1>Research Interests</h1>
        <p>My research centers on advancing <strong>self-supervised learning (SSL)</strong> and <strong>representation learning</strong> for complex, temporal, and multimodal data â€” with strong emphasis on <strong>spatiotemporal modeling</strong> and <strong>remote sensing</strong>. Building on my PhD work in <em>Spatio-Temporal Data (STD)</em>, I investigate how cutting-edge SSL approaches â€” originally developed for vision and language â€” can be adapted to time series, satellite imagery, and other domain-specific modalities.</p>
        <hr>
        <h2>ğŸ§  Core Research Areas</h2>
        <h3>Self-Supervised &amp; Representation Learning</h3>
        <p>I design SSL frameworks that enable models to learn rich, meaningful representations directly from unlabeled data. This includes:</p>
        <ul>
            <li><strong>Temporal dependencies</strong> in sequential and environmental data</li>
            <li><strong>Cross-modal relations</strong> between spatial, spectral, and temporal sources</li>
            <li><strong>Contextual and structural patterns</strong> without manual annotation</li>
            <li><strong>Invariant and generalizable features</strong> across transformations and domains</li>
        </ul>
        <p>By leveraging contrastive learning, masked modeling, reconstruction tasks, and hybrid SSL strategies, my goal is to enable autonomous discovery of structure across diverse datasets.</p>
        <h3>Modern and Hybrid Architectures</h3>
        <p>A central focus of my work is exploring modern architectures that enhance SSL for temporal and multimodal data:</p>
        <ul>
            <li><strong>ğŸ” Attention Mechanisms</strong> â€” capturing long-range and cross-modal relationships</li>
            <li><strong>ğŸ¤– Transformers</strong> â€” flexible sequence modeling for images, time series, and multimodal data</li>
            <li><strong>âš¡ State-Space Models (SSMs)</strong> â€” efficient modeling of long sequences</li>
            <li><strong>ğŸŒŠ Differential-equation &amp; signal-processing inspired modules</strong> â€” combining deep learning with principled dynamical modeling</li>
        </ul>
        <p>These approaches enable efficient, interpretable, and scalable representations for real-world large-scale datasets.</p>
        <h3>Multimodal Spatio-Temporal Learning</h3>
        <p>I research methods for jointly learning from multiple data modalities, including:</p>
        <ul>
            <li><strong>Multispectral + spatial data</strong> (e.g., remote sensing imagery)</li>
            <li><strong>Time series + metadata/context</strong> (environmental, ecological, or sensor data)</li>
            <li><strong>Video + temporal patterns</strong> (e.g., temporal consistency, motion-aware features)</li>
        </ul>
        <p>The aim is to design unified, modality-agnostic representation spaces that effectively fuse complementary information.</p>
        <hr>
        <h2>ğŸ¯ Application Domains</h2>
        <h3>Remote Sensing &amp; Earth Observation</h3>
        <ul>
            <li>Multispectral and multitemporal image analysis</li>
            <li>Land-use/land-cover classification</li>
            <li>Environmental monitoring and change detection</li>
            <li>Vegetation and phenology time series modeling</li>
        </ul>
        <h3>Time Series &amp; Spatiotemporal Data</h3>
        <ul>
            <li>Temporal representation learning</li>
            <li>Forecasting and anomaly detection</li>
            <li>Pattern discovery in long-term environmental data</li>
            <li>SSL for irregular, multimodal time series</li>
        </ul>
        <h3>Computer Vision &amp; Video Understanding</h3>
        <ul>
            <li>Video representation learning (e.g., colorization, temporal consistency)</li>
            <li>Cross-domain transfer from vision to remote sensing</li>
            <li>Spatiotemporal feature extraction and modeling</li>
        </ul>
        <h3>Domain-Specific Scientific &amp; Environmental AI</h3>
        <ul>
            <li>Ecological and environmental data modeling</li>
            <li>Agricultural and biodiversity analysis</li>
            <li>Scientific data-driven discovery</li>
            <li>Interdisciplinary ML for Earth sciences</li>
        </ul>
        <hr>
        <h2>ğŸš€ Research Philosophy</h2>
        <p>My broader research philosophy emphasizes:</p>
        <ol>
            <li><strong>Adaptability</strong> â€” models that generalize across datasets, regions, and modalities</li>
            <li><strong>Generalization</strong> â€” robust performance in low-label and cross-domain settings</li>
            <li><strong>Interpretability</strong> â€” representations that offer scientific insight</li>
            <li><strong>Scalability</strong> â€” computationally efficient solutions for large-scale data</li>
        </ol>
        <p>My long-term goal is to develop <strong>generalizable, interpretable, and scalable</strong> learning frameworks that bridge modern machine learning with scientific discovery in remote sensing and environmental domains.</p>
        <hr>
        <h2>ğŸ¨ The Fun Side of Research</h2>
        <p>I value creativity and openness in research:</p>
        <ul>
            <li>ğŸ¨ <strong>Beautiful visualizations</strong> to make complex ideas intuitive</li>
            <li>ğŸ® <strong>Interactive demos</strong> for practical exploration</li>
            <li>ğŸ¤ <strong>Open collaboration and open-source contributions</strong></li>
            <li>ğŸŒŸ <strong>Creative thinking</strong> â€” blending ideas across fields</li>
        </ul>
        <hr>
        <p><em>Interested in collaboration? Feel free to reach out â€” Iâ€™m always open to interdisciplinary work, open-source projects, and scientific partnerships.</em></p>
    </div>
</article>
