---
layout: default
title: Publications - Leandro Stival
description: Leandro Stival - Ph.D. in Computer Science specializing in Self-Supervised Learning
keywords: machine learning, deep learning, computer vision, video colorization, self-supervised learning, research, AI
---
<article class="page-content">
    <header class="page-header">
        <h1>Publications</h1>
    </header>

    <div class="page-body">
        <h1>Publications</h1>
        <p>Here you'll find my research publications in Machine Learning, Computer Vision, and Video Colorization. Click on the titles to access the full papers, and use the BibTeX citations for your references.</p>
        <hr>
        <h2>2025</h2>
        <h3>Semantically-Aware Contrastive Learning for Multispectral Remote Sensing Images</h3>
        <p><strong>ISPRS Journal of Photogrammetry and Remote Sensing (May 2025)</strong></p>
        <p><strong>Authors:</strong> L. Stival, R. da Silva Torres, H. Pedrini</p>
        <p>This work introduces a semantically-aware contrastive learning approach for multispectral remote sensing images, advancing self-supervised learning techniques in the remote sensing domain.</p>
        <p><a href="https://www.sciencedirect.com/science/article/pii/S0924271625000826">ðŸ“„ Paper</a> <a href="https://www.researchgate.net/publication/391354860_Semantically-Aware_Contrastive_Learning_for_multispectral_remote_sensing_images">ðŸ”— ResearchGate</a></p>
        <h5>BibTeX Citation</h5>
        <div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">stival2025semantically</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Semantically-Aware Contrastive Learning for multispectral remote sensing images}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Stival, L. and da Silva Torres, R. and Pedrini, H.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{ISPRS Journal of Photogrammetry and Remote Sensing}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2025}</span><span class="p">,</span>
<span class="w">  </span><span class="na">month</span><span class="p">=</span><span class="s">{May}</span>
<span class="p">}</span>
</code></pre></div>

        <hr>
        <h3>CVC: Contrastive Autoencoders for Video Colorization</h3>
        <p><strong>Intelligent Systems and Applications: Proceedings of the 2025 Intelligent Systems Conference (IntelliSys)</strong></p>
        <p><strong>Authors:</strong> L. Stival, R. da Silva Torres, H. Pedrini</p>
        <p>This paper presents a novel contrastive autoencoder approach for video colorization, leveraging self-supervised learning to improve temporal consistency and color accuracy.</p>
        <p><a href="https://link.springer.com/chapter/10.1007/978-3-032-00071-2_24">ðŸ“„ Paper</a>
        <a href="https://www.researchgate.net/publication/394848506_CVC_Contrastive_Autoencoders_for_Video_Colorization">ðŸ”— ResearchGate</a>
        <a href="https://research.wur.nl/en/publications/cvc-contrastive-autoencoders-forvideo-colorization/">ðŸŒ± Wur Research Portal</a></p>
        <h5>BibTeX Citation</h5>
        <div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">stival2025cvc</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{CVC: Contrastive Autoencoders for Video Colorization}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Stival, L. and da Silva Torres, R. and Pedrini, H.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{Intelligent Systems and Applications: Proceedings of the 2025 Intelligent Systems Conference (IntelliSys)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2025}</span>
<span class="p">}</span>
</code></pre></div>

        <hr>
        <h2>2024</h2>
        <h3>CAVC: Cosine Attention Video Colorization</h3>
        <p><strong>VISAPP 2024 - 19th International Conference on Computer Vision Theory and Applications</strong></p>
        <p><strong>Authors:</strong> L. Stival, R. S. da Torres, H. Pedrini</p>
        <p><strong>Conference:</strong> Rome, Italy, February 27-29, 2024</p>
        <p>This paper proposes a novel approach to video colorization utilizing a single attention head with shared weights and cosine similarity for refining monochromatic frames. The architecture was trained on DAVIS, UVO, and LDV datasets and achieved superior results compared to state-of-the-art models in terms of the FID metric.</p>
        <h4>Abstract</h4>
        <p>Example-based video colorization methods use a reference image to colorize a monochromatic video. This paper proposes CAVC (Cosine Attention Video Colorization), which uses a single attention head with shared weights and cosine similarity for refining monochromatic frames as a pre-processing step for an autoencoder that performs feature fusion. The architecture achieves state-of-the-art performance on multiple benchmark datasets.</p>
        <p><a href="https://www.scitepress.org/Papers/2024/123485/123485.pdf">ðŸ“„ Paper</a> | <a href="https://www.researchgate.net/publication/378702893_CAVC_Cosine_Attention_Video_Colorization">ðŸ”— ResearchGate</a> | <a href="https://research.wur.nl/en/publications/cavc-cosine-attention-video-colorization/">ðŸŒ± Wur Research Portal</a></p>
        <h5>BibTeX Citation</h5>
        <div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">stival2024cavc</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{CAVC: Cosine Attention Video Colorization}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Stival, L. and da Torres, R. S. and Pedrini, H.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{Proceedings of the 19th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications: Volume 3: VISAPP}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span><span class="p">,</span>
<span class="w">  </span><span class="na">address</span><span class="p">=</span><span class="s">{Rome, Italy}</span>
<span class="p">}</span>
</code></pre></div>

        <hr>
        <h3>Enhancing Video Colorization with Deep Learning: A Comprehensive Analysis of Training Loss Functions</h3>
        <p><strong>Intelligent Systems and Applications: Proceedings of the 2024 Intelligent Systems Conference (IntelliSys)</strong></p>
        <p><strong>Authors:</strong> L. Stival, R. da Silva Torres, H. Pedrini</p>
        <p>This work provides a comprehensive analysis of different training loss functions for video colorization using deep learning, offering insights into which loss functions perform best for different scenarios.</p>
        <p><a href="https://link.springer.com/chapter/10.1007/978-3-031-66329-1_32">ðŸ“„ Paper</a> | <a href="https://www.researchgate.net/publication/382709737_Enhancing_Video_Colorization_with_Deep_Learning_A_Comprehensive_Analysis_of_Training_Loss_Functions">ðŸ”— ResearchGate</a> | <a href="https://research.wur.nl/en/publications/enhancing-video-colorization-with-deep-learning-a-comprehensive-a/">ðŸŒ± Wur Research Portal</a></p>
        <h5>BibTeX Citation</h5>
        <div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">stival2024enhancing</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Enhancing Video Colorization with Deep Learning: A Comprehensive Analysis of Training Loss Functions}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Stival, L. and da Silva Torres, R. and Pedrini, H.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{Intelligent Systems and Applications: Proceedings of the 2024 Intelligent Systems Conference IntelliSys}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span>
<span class="p">}</span>
</code></pre></div>

        <hr>
        <h3>Video Colorization Based on a Diffusion Model Implementation</h3>
        <p><strong>Intelligent Systems and Applications: Proceedings of the 2024 Intelligent Systems Conference (IntelliSys)</strong></p>
        <p><strong>Authors:</strong> L. Stival, R. da Silva Torres, H. Pedrini</p>
        <p>This paper explores the application of diffusion models to video colorization, demonstrating how these generative models can be adapted for temporal consistency in video processing.</p>
        <p><a href="https://link.springer.com/chapter/10.1007/978-3-031-66329-1_10">ðŸ“„ Paper</a> | <a href="https://www.researchgate.net/publication/382735219_Video_Colorization_Based_on_a_Diffusion_Model_Implementation">ðŸ”— ResearchGate</a> | <a href="https://research.wur.nl/en/publications/video-colorization-based-onadiffusion-model-implementation/">ðŸŒ± Wur Research Portal</a></p>
        <h5>BibTeX Citation</h5>
        <div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">stival2024video</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Video Colorization Based on a Diffusion Model Implementation}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Stival, L. and da Silva Torres, R. and Pedrini, H.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{Intelligent Systems and Applications: Proceedings of the 2024 Intelligent Systems Conference IntelliSys}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2024}</span>
<span class="p">}</span>
</code></pre></div>

        <hr>
        <h2>2023</h2>
        <h3>SwinFVC: A Swin Flow Video Colorization Example-Based Method</h3>
        <p><strong>2023 International Conference on Machine Learning and Applications (ICMLA)</strong></p>
        <p><strong>Authors:</strong> L. Stival, R. D. S. Torres, H. Pedrini</p>
        <p>This work presents SwinFVC, an example-based video colorization method that leverages Swin Transformer architecture and optical flow to achieve high-quality temporal consistency in colorized videos.</p>
        <p><a href="https://ieeexplore.ieee.org/abstract/document/10459909?casa_token=kgDVr7vaZK0AAAAA:1RpMPNxYDipr2qEuaWJ95yDRukYWbdxcAJWleftuoWi_ZKbU1OIRP_U0qQXJkF9RN9lN_ay1em8M9w">ðŸ“„ Paper</a>| <a href="https://www.researchgate.net/publication/379091789_SwinFVC_A_Swin_Flow_Video_Colorization_Example-Based_Method">ResearchGate</a> | <a href="https://edepot.wur.nl/673002">ðŸŒ± Wur Research Portal</a></p>
        <h5>BibTeX Citation</h5>
        <div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">stival2023swinfvc</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{SwinFVC: A swin flow video colorization example-based method}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Stival, L. and Torres, R. D. S. and Pedrini, H.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="p">=</span><span class="s">{2023 International Conference on Machine Learning and Applications (ICMLA)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2023}</span>
<span class="p">}</span>
</code></pre></div>

        <hr>
        <h3>Survey on Video Colorization: Concepts, Methods and Applications</h3>
        <p><strong>Journal of Signal Processing Systems, Volume 95, Issue 6</strong></p>
        <p><strong>Authors:</strong> L. Stival, H. Pedrini</p>
        <p><strong>Published:</strong> May 2023</p>
        <p>This comprehensive survey analyzes state-of-the-art techniques in video colorization, including commonly used colorization and machine learning techniques, as well as color space and correlated methods to enhance results. Unlike other reviews, this paper focuses on solutions for both natural video and animation, highlighting the unique challenges of achieving temporal color consistency.</p>
        <h4>Abstract</h4>
        <p>Video colorization is a challenging task that involves adding color information to grayscale video sequences. This survey provides a comprehensive analysis of state-of-the-art techniques, covering both traditional and deep learning-based approaches. We discuss the main challenges, including temporal consistency, and review methods for both natural videos and animation.</p>
        <p><a href="https://link.springer.com/article/10.1007/s11265-023-01872-w">ðŸ“„ Paper</a> | <a href="https://www.researchgate.net/publication/370808978_Survey_on_Video_Colorization_Concepts_Methods_and_Applications">ResearchGate</a></p>
        <h5>BibTeX Citation</h5>
        <div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">stival2023survey</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Survey on video colorization: concepts, methods and applications}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Stival, L. and Pedrini, H.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{Journal of Signal Processing Systems}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="p">=</span><span class="s">{95}</span><span class="p">,</span>
<span class="w">  </span><span class="na">number</span><span class="p">=</span><span class="s">{6}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2023}</span><span class="p">,</span>
<span class="w">  </span><span class="na">month</span><span class="p">=</span><span class="s">{May}</span>
<span class="p">}</span>
</code></pre></div>

        <hr>
        <h3>Using Machine Learning Pipeline to Predict Entry into the Attack Zone in Football</h3>
        <p><strong>PLOS ONE</strong></p>
        <p><strong>Authors:</strong> L. Stival, A. Pinto, F. dos Santos Pinto de Andrade, P. R. P. Santiago, H. Biermann, R. da Silva Torres, U. Dias</p>
        <p><strong>Published:</strong> January 18, 2023</p>
        <p>This research focuses on determining if analyzing the first five seconds after a team gains ball possession provides enough information to predict whether the ball will reach the final quarter of the soccer field. The methodology models players' interactions as graph structures and extracts metrics, encoding them into two-dimensional representations of visual rhythms for feature extraction through deep convolutional networks.</p>
        <h4>Abstract</h4>
        <p>This paper presents a machine learning pipeline to predict entry into the attack zone in football by analyzing the initial moments of ball possession. We model player interactions as graph structures and use deep convolutional networks to predict offensive outcomes. Our findings indicate that offensive play near the opponent's penalty area can be predicted by observing the initial five seconds of ball possession.</p>
        <p><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0265372">ðŸ“„ Paper</a> | <a href="https://www.researchgate.net/publication/367252180_Using_machine_learning_pipeline_to_predict_entry_into_the_attack_zone_in_football">ResearchGate</a></p>
        <h5>BibTeX Citation</h5>
        <div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">stival2023ml</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{Using machine learning pipeline to predict entry into the attack zone in football}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Stival, L. and Pinto, A. and de Andrade, F. dos Santos Pinto and Santiago, P. R. P. and Biermann, H. and da Silva Torres, R. and Dias, U.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{PLOS ONE}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2023}</span><span class="p">,</span>
<span class="w">  </span><span class="na">month</span><span class="p">=</span><span class="s">{January}</span><span class="p">,</span>
<span class="w">  </span><span class="na">day</span><span class="p">=</span><span class="s">{18}</span>
<span class="p">}</span>
</code></pre></div>

        <hr>
        <h2>Research Metrics</h2>
        <p><strong>Total Publications:</strong> 8<br>
        <strong>Research Areas:</strong> Machine Learning, Computer Vision, Video Colorization, Self-Supervised Learning, Remote Sensing, Sports Analytics</p>
        <p><em>For a complete and up-to-date list of publications, please visit my <a href="https://scholar.google.com/citations?user=Bw3dn34AAAAJ&amp;hl=en">Google Scholar</a> profile or <a href="https://www.wur.nl/en/persons/leandro-stival.htm">WUR Profile</a>.</em></p>
    </div>
</article>
